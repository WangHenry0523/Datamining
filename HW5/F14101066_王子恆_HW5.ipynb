{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpsF5CYXt0KH"
      },
      "source": [
        "## Section 1: Similarity Computations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jytsQjGut7tB"
      },
      "source": [
        "### 1.a Jaccard Similarity (Users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#from sklearn.metrics import jaccard_score\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "最相似的使用者:\n",
            "\n",
            "Willy & Xavier::0.75\n"
          ]
        }
      ],
      "source": [
        "users_watch={   \"Willy\":  [1,1,1,0,1],\n",
        "                \"Xavier\": [1,1,1,0,0],\n",
        "                \"Yvonne\": [0,1,1,1,0],\n",
        "                \"Zac\":    [1,1,0,1,1]\n",
        "            }\n",
        "def jaccardscore(u1,u2,matrix):\n",
        "    user1=matrix[u1]\n",
        "    user2=matrix[u2]\n",
        "    intersection = sum([i & j for i, j in zip(user1, user2)])\n",
        "    union = sum([i | j for i ,j  in zip(user1,user2)])\n",
        "    return intersection/union if union !=0 else 0\n",
        "# 所有使用者名稱\n",
        "user_names = list(users_watch.keys())\n",
        "user_watch_jaccardscore={}\n",
        "# 計算兩兩組合的 Jaccard 相似度\n",
        "for u1, u2 in combinations(user_names, 2):\n",
        "    score = jaccardscore(u1, u2,users_watch)\n",
        "    pair=f\"{u1} & {u2}:\"\n",
        "    user_watch_jaccardscore[pair] = score\n",
        "    #print(f\"{u1} & {u2} : Jaccard similarity = {score:.2f}\")\n",
        "max_score=max(user_watch_jaccardscore.values())\n",
        "max_score_pair=[pair for pair,score in user_watch_jaccardscore.items() if score==max_score]\n",
        "print(\"最相似的使用者:\\n\")\n",
        "for i in max_score_pair:\n",
        "    print(f\"{i}:{max_score}\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-18miLyvuCA3"
      },
      "source": [
        "### 1.b Jaccard Similarity (Movies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "最相似的電影:\n",
            "\n",
            "La La Land & The Lion King::0.75\n",
            "The Lion King & Parasite::0.75\n"
          ]
        }
      ],
      "source": [
        "movie_watch={   \"La La Land\":    [1,1,0,1],\n",
        "                \"The Lion King\": [1,1,1,1],\n",
        "                \"Parasite\":      [1,1,1,0],\n",
        "                \"Joker\":         [0,0,1,1],\n",
        "                \"John Wick3\":    [1,0,0,1]\n",
        "            }\n",
        "movie_names = list(movie_watch.keys())\n",
        "movie_watch_jaccardscore={}\n",
        "\n",
        "for u1, u2 in combinations(movie_names, 2):\n",
        "    score = jaccardscore(u1, u2,movie_watch)\n",
        "    pair=f\"{u1} & {u2}:\"\n",
        "    movie_watch_jaccardscore[pair] = score\n",
        "\n",
        "max_score=max(movie_watch_jaccardscore.values())\n",
        "max_score_pair=[pair for pair,score in movie_watch_jaccardscore.items() if score==max_score]\n",
        "print(\"最相似的電影:\\n\")\n",
        "for i in max_score_pair:\n",
        "    print(f\"{i}:{max_score}\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW4Hn-9luQ6o"
      },
      "source": [
        "### 1.c Pearson Correlation (Users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import pearsonr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pearson 最相似的使用者配對：\n",
            "Willy & Yvonne : 1.00\n",
            "Willy & Zac : 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2408\\2038560187.py:17: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  return pearsonr(r1, r2)[0]  # Pearson correlation\n"
          ]
        }
      ],
      "source": [
        "user_rating={\n",
        "    \"Willy\"  : [5,5,4,None,4],\n",
        "    \"Xavier\" : [1,2,2,None,None],\n",
        "    \"Yvonne\" : [None,2,1,5,None],\n",
        "    \"Zac\"    : [2,2,None,1,1]\n",
        "}\n",
        "def pearson_similarity(u1, u2):\n",
        "    r1 = user_rating[u1]\n",
        "    r2 = user_rating[u2]\n",
        "    \n",
        "    # 只保留兩人都評分的電影\n",
        "    paired_ratings = [(x, y) for x, y in zip(r1, r2) if x is not None and y is not None]\n",
        "    if len(paired_ratings) < 2:\n",
        "        return 0  # 太少資料無法算 Pearson\n",
        "    r1,r2 = zip(*paired_ratings)\n",
        "    \n",
        "    return pearsonr(r1, r2)[0]  # Pearson correlation\n",
        "\n",
        "user_names = list(user_rating.keys())\n",
        "pearson_scores = {}\n",
        "\n",
        "for u1, u2 in combinations(user_names, 2):\n",
        "    score = pearson_similarity(u1, u2)\n",
        "    pearson_scores[f\"{u1} & {u2}\"] = score\n",
        "\n",
        "# 找出最大值\n",
        "max_score = max(pearson_scores.values())\n",
        "most_similar_pairs = [pair for pair, score in pearson_scores.items() if score == max_score]\n",
        "\n",
        "print(\"\\nPearson 最相似的使用者配對：\")\n",
        "for pair in most_similar_pairs:\n",
        "    print(f\"{pair} : {max_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A35JdiwDu3JY"
      },
      "source": [
        "## Section 2: Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### A:T(ii)的意義為使用者i喜歡T(ii)個項目，T(ij)的意義為使用者i和使用者j同時喜歡T(ij)個項目。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A:見pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A:見pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l-jQdvgvF3C"
      },
      "source": [
        "### 2.d Application to Real Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"FOX 28 News at 10pm\":預測分數 908.48\n",
            "\"Family Guy\":預測分數 861.18\n",
            "\"2009 NCAA Basketball Tournament\":預測分數 827.60\n",
            "\"NBC 4 at Eleven\":預測分數 784.78\n",
            "\"Two and a Half Men\":預測分數 757.60\n"
          ]
        }
      ],
      "source": [
        "user_show=[]\n",
        "with open('user-shows.txt') as users:\n",
        "    for line in users:\n",
        "        user_show.append([int(x) for x in line.split()])\n",
        "shows=[]\n",
        "with open('shows.txt') as show:\n",
        "    for line in show:\n",
        "        shows.append(line.strip())\n",
        "\n",
        "# Jim前100部節目設為0\n",
        "user_show_masked = user_show.copy()\n",
        "jim = user_show[499].copy()\n",
        "for i in range(100):\n",
        "    jim[i] = 0\n",
        "user_show_masked[499] = jim\n",
        "# 轉NumPy\n",
        "R=np.array(user_show_masked)\n",
        "# 計算 cosine similarity\n",
        "S_u=cosine_similarity(R)\n",
        "# 預測分數矩陣 Γ_U\n",
        "Gamma_U = S_u@R\n",
        "# 取出 Jim 的推薦分數（前100個）\n",
        "jim_predict = Gamma_U[499]\n",
        "# 推薦前 5 部節目\n",
        "top_5=heapq.nlargest(5, range(100), key=lambda i: jim_predict[i])\n",
        "for i in top_5:\n",
        "    print(f\"{shows[i]}:預測分數 {jim_predict[i]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "項目－項目協同過濾推薦：\n",
            "\"FOX 28 News at 10pm\":預測分數 31.36\n",
            "\"Family Guy\":預測分數 30.00\n",
            "\"NBC 4 at Eleven\":預測分數 29.40\n",
            "\"2009 NCAA Basketball Tournament\":預測分數 29.23\n",
            "\"Access Hollywood\":預測分數 28.97\n"
          ]
        }
      ],
      "source": [
        "# 使用者-項目矩陣\n",
        "R = np.array(user_show)\n",
        "# 先備份 Jim 原始行為（之後要比對正確性）\n",
        "jim_original = R[499].copy()\n",
        "\n",
        "# 將前 100 部節目設為未知（masking）\n",
        "R[499, :100] = 0\n",
        "\n",
        "# 每個「項目」是 R 的一欄\n",
        "# 轉置後，每列代表一個項目，計算 item-item cosine\n",
        "S_i = cosine_similarity(R.T)\n",
        "\n",
        "# 計算 Jim 的推薦分數（向量）\n",
        "jim_scores_item = R[499] @ S_i  # shape: (num_items,)\n",
        "\n",
        "# 只挑前 100 部節目\n",
        "top_100_scores = jim_scores_item[:100]\n",
        "\n",
        "# 取推薦分數前 5 高的節目 index\n",
        "top_5= heapq.nlargest(5, range(100), key=lambda i: top_100_scores[i])\n",
        "\n",
        "# 顯示推薦結果\n",
        "print(\"項目－項目協同過濾推薦：\")\n",
        "for idx in top_5:\n",
        "    print(f\"{shows[idx]}:預測分數 {top_100_scores[idx]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZIk3D-evScd"
      },
      "source": [
        "## Section 3: Latent Factor Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 見pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNIXKgKVvak0"
      },
      "source": [
        "### 3.b Implementation and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_matrix_size(file):\n",
        "    max_user_id=0\n",
        "    max_item_id=0\n",
        "    with open(file) as rating:\n",
        "        for line in rating:\n",
        "            user_id, item_id, _ = map(int, line.strip().split())\n",
        "            if user_id > max_user_id:\n",
        "                max_user_id = user_id\n",
        "            if item_id > max_item_id:\n",
        "                max_item_id = item_id\n",
        "    return max_user_id, max_item_id\n",
        "\n",
        "def init_matrix(num_user,num_item,k=20):\n",
        "    limit = np.sqrt(5/k)\n",
        "    P=np.random.uniform(0,limit,(num_user+1,k))\n",
        "    Q=np.random.uniform(0,limit,(num_item+1,k))\n",
        "    return P,Q\n",
        "\n",
        "def SGD(file,P,Q,η=0.05,λ=0.1, iter=40):\n",
        "    error=[]\n",
        "    for epoch in range(iter):\n",
        "        with open(file,'r') as f:\n",
        "            for line in f:\n",
        "                user,item,rate=map(int,line.strip().split())\n",
        "                err=rate-np.dot(P[user],Q[item])\n",
        "                P[user] += η*(err*Q[item] - λ*P[user])\n",
        "                Q[item] += η*(err*P[user]-λ*Q[item])\n",
        "        total_error=0\n",
        "        with open(file,'r') as f:\n",
        "            for line in f:\n",
        "                user,item,rate=map(int,line.strip().split())\n",
        "                predict=np.dot(P[user],Q[item])\n",
        "                total_error += (rate-predict)**2\n",
        "        total_error += λ * (np.sum(np.linalg.norm(P, axis=1) ** 2) + np.sum(np.linalg.norm(Q, axis=1) ** 2))\n",
        "        error.append(total_error)\n",
        "    return error\n",
        "\n",
        "filename='ratings.train.txt'\n",
        "max_user_num,max_item_num=get_matrix_size(filename)\n",
        "P,Q=init_matrix(max_user_num,max_item_num)\n",
        "list_η=[0.1,0.05,0.02,0.01,0.001]\n",
        "n_error_list=[]\n",
        "for η in list_η:\n",
        "    P, Q = init_matrix(max_user_num, max_item_num)  # 每次重新初始化\n",
        "    error_list = SGD(filename, P, Q, η)\n",
        "    n_error_list.append(error_list)\n",
        "    print(f'η={η}, min total error: {min(error_list):.2f}')\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "for i, η in enumerate(list_η):\n",
        "    plt.plot(range(1, 1 + len(n_error_list[i])), n_error_list[i], label=f\"η = {η}\")\n",
        "plt.title('SGD curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Total error')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A:從SGD圖中可以看出當η=0.1時，P、Q矩陣中就因為err太大而overflow，因此學習率太高似乎並不是一個很好的選擇。而看到其他四個學習率都能有效把總Error降低到65000以下，在這四個裡面當我們挑選η=0.05時大約在epoch=10時就已經收斂完成了，若想在短時間內執行完畢會是一個較好選擇，而當我們的η=0.02時，雖然一直到epoch=25時才收歛的優於η=0.05，但它可以提供最低的Total Error確實很好，若想追求最佳解會是一個最好的選擇。而比0.02更低的學習率則會因為更新太慢反而無法及時收斂至最佳解，並不推薦使用。綜合而言，我認為η=0.05會是一個最好的選擇，因為它能在最快的時間內提供相對較優的答案，兼具準確度與速度。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datamining",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
