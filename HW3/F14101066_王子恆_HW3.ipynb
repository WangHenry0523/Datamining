{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d3891d0",
   "metadata": {},
   "source": [
    "## 1  Evaluation Metrics (20 %)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11aa5a",
   "metadata": {},
   "source": [
    "### 1.1  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a6f41",
   "metadata": {},
   "source": [
    "#### Answer:<br>因為信賴度的公式為 P(A ∩ B)/P(A)，但我們並沒有考慮到B獨立發生的情況，若P(B)本身就很大同時也會造成信賴度變大，換句話說，我們無法從信賴度中看出A、B是否真的有關係，或只是因為P(B)很大所造成的巧合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29ad98",
   "metadata": {},
   "source": [
    "### 1.2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04ea53",
   "metadata": {},
   "source": [
    "#### Answer:<br>提升度與確信度不受影響的原因在於，提升度的公式有考慮到P(B)的獨立機率，當B、A兩者獨立的時候提升度為1，所以當我們看到提升度大於1時，表示A確實能有效提升，確信度的部分，從定義來看確信度是指當A發生而B沒有發生與B本就不發生的情況相比，它是有考慮到B的獨立機率的(從1-P(B))，有就是當P(B)很高時，信賴度會連帶被提高，但確信度的分母(1-confi(A->B))也會同時變小，因為B本來就很常發生，只有當「B 發生的機率因 A 的出現而大幅改變」時，它才會變大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947266c",
   "metadata": {},
   "source": [
    "### 1.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e31d9",
   "metadata": {},
   "source": [
    "#### Answer:<br>1.信賴度為非對稱的，從公式推導可知，confidence(A->B)=P(A ∩ B)/P(A) confidence(B->A)=P(A ∩ B)/P(B)，也就是說除非P(A)=P(B)的特例之外都不會相等。<br>2.提升度為對稱的，從公式推導可知，lift(A->B)=P(A ∩ B)/(P(B)*P(A))，而lift(B->A)的分母因為乘法的交換律所以是相等的<br>3.確信度是非對稱的，從公式推導可知，分子在算conviction(A->B)時為1-P(B)而(B->A)時為1-P(A)，分母用到的信賴度也並非對稱的，因此除非P(A)=P(B)的特例之外都不會相等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7dfb77",
   "metadata": {},
   "source": [
    "### 1.4  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5868eee",
   "metadata": {},
   "source": [
    "#### Answer:<br>1.信賴度有達到最大值，因為信賴度的定義本身值域就是0->1。<br>2.提升度有達到最大值，當confidence為1時，Lift=1/P(B)，當P(B)非常小時Lift可以趨近無限大，也就是雖然B不常發生，但A發生時總伴隨B這樣的強規則。<br>3.確信度有達到最大值，從公式的分母來看1-confidence(A->B)為0，所以確信度趨近無限大，這代表當A發生時B一定發生且不可能違反(conviction=無限大)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ada31",
   "metadata": {},
   "source": [
    "## 2  Application in Recommending Items (30 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c991c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from apyori import apriori \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc69044e",
   "metadata": {},
   "source": [
    "### 2.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c368f100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: DAI93865 -> FRO40251, Confidence: 1.0\n",
      "Items: FRO40251 -> GRO85051, Confidence: 0.9991762767710051\n",
      "Items: FRO40251 -> GRO38636, Confidence: 0.9906542056074765\n",
      "Items: ELE12951 -> FRO40251, Confidence: 0.9905660377358491\n",
      "Items: DAI88079 -> FRO40251, Confidence: 0.9867256637168142\n"
     ]
    }
   ],
   "source": [
    "transaction=[]\n",
    "browsing=open('browsing.txt','r')\n",
    "for line in browsing:\n",
    "    item=line.strip().split()\n",
    "    transaction.append(item)\n",
    "\n",
    "associationRule=apriori(\n",
    "    transaction,\n",
    "    min_support=100/len(transaction),\n",
    "    min_length=1,\n",
    "    max_length=2)\n",
    "associationResults=list(associationRule)\n",
    "rules={}\n",
    "for rule in associationResults[647:]:\n",
    "    max_confidence=0\n",
    "    best_items=None\n",
    "    for ordered_statistic in rule.ordered_statistics[1:3]:\n",
    "        base=set(ordered_statistic.items_base)\n",
    "        add=set(ordered_statistic.items_add)\n",
    "\n",
    "        confidence=ordered_statistic.confidence\n",
    "\n",
    "        if(confidence>=max_confidence):\n",
    "            max_confidence=confidence\n",
    "            best_items = tuple(sorted(base.union(add)))  \n",
    "    \n",
    "    if best_items is not None:\n",
    "        rules[best_items] = max_confidence\n",
    "\n",
    "for items, confidence in sorted(rules.items(), key=lambda x: (-x[1], x[0]))[:5]:\n",
    "    print(f\"Items: {items[0]} -> {items[1]}, Confidence: {confidence}\")\n",
    "\n",
    "browsing.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e795db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: ['DAI93865'] => ['FRO40251'], Confidence: 1.0\n",
      "Items: ['GRO85051'] => ['FRO40251'], Confidence: 0.9991762767710051\n",
      "Items: ['GRO38636'] => ['FRO40251'], Confidence: 0.9906542056074765\n",
      "Items: ['ELE12951'] => ['FRO40251'], Confidence: 0.9905660377358491\n",
      "Items: ['DAI88079'] => ['FRO40251'], Confidence: 0.9867256637168142\n"
     ]
    }
   ],
   "source": [
    "transaction=[]\n",
    "browsing=open('browsing.txt','r')\n",
    "for line in browsing:\n",
    "    item=line.strip().split()\n",
    "    transaction.append(item)\n",
    "\n",
    "encoder = TransactionEncoder()\n",
    "encoded_transaction = encoder.fit_transform(transaction)\n",
    "\n",
    "# 将转换后的数据转换为DataFrame\n",
    "df = pd.DataFrame(encoded_transaction, columns=encoder.columns_)\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=100/len(transaction),max_len=2,use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "filtered_itemsets = frequent_itemsets[(frequent_itemsets['length'] == 2)]\n",
    "\n",
    "# 3. 生成关联规则\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "# 5. 提取並排序結果\n",
    "# 根据信賴度降序排序，信賴度相同的按字典順序排序\n",
    "sorted_rules = rules.sort_values(by=[\"confidence\", \"antecedents\"], ascending=[False, True])\n",
    "\n",
    "# 6. 打印前五個規則及其信賴度\n",
    "for index, row in sorted_rules.head(5).iterrows():\n",
    "    antecedents = list(row[\"antecedents\"])\n",
    "    consequents = list(row[\"consequents\"])\n",
    "    confidence = row[\"confidence\"]\n",
    "    print(f\"Items: {antecedents} => {consequents}, Confidence: {confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8377afb0",
   "metadata": {},
   "source": [
    "### 2.2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b2afc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: ('DAI23334', 'DAI62779') -> ELE92920, Confidence: 1.0\n",
      "Items: ('DAI31081', 'FRO40251') -> GRO85051, Confidence: 1.0\n",
      "Items: ('DAI55911', 'FRO40251') -> GRO85051, Confidence: 1.0\n",
      "Items: ('DAI62779', 'DAI88079') -> FRO40251, Confidence: 1.0\n",
      "Items: ('DAI75645', 'FRO40251') -> GRO85051, Confidence: 1.0\n"
     ]
    }
   ],
   "source": [
    "transaction=[]\n",
    "browsing=open('browsing.txt','r')\n",
    "for line in browsing:\n",
    "    item=line.strip().split()\n",
    "    transaction.append(item)\n",
    "\n",
    "associationRule=apriori(\n",
    "    transaction,\n",
    "    min_support=100/len(transaction),\n",
    "    min_length=2,\n",
    "    max_length=3)\n",
    "associationResults=list(associationRule)\n",
    "\n",
    "rules={}\n",
    "for rule in associationResults[1981:]:\n",
    "    max_confidence=0\n",
    "    best_items=None\n",
    "    for ordered_statistic in rule.ordered_statistics[4:7]:\n",
    "        base=set(ordered_statistic.items_base)\n",
    "        add=set(ordered_statistic.items_add)\n",
    "\n",
    "        confidence=ordered_statistic.confidence\n",
    "\n",
    "        if(confidence>=max_confidence):\n",
    "            max_confidence=confidence\n",
    "            best_items = tuple(sorted(base.union(add)))  \n",
    "    \n",
    "    if best_items is not None:\n",
    "        rules[best_items] = max_confidence\n",
    "\n",
    "for items, confidence in sorted(rules.items(), key=lambda x: (-x[1], x[0]))[:5]:\n",
    "    print(f\"Items: {items[0:2]} -> {items[2]}, Confidence: {confidence}\")\n",
    "        \n",
    "\n",
    "browsing.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c37c602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: ['ELE26917', 'GRO85051'] => ['FRO40251'], Confidence: 1.0\n",
      "Items: ['FRO53271', 'GRO85051'] => ['FRO40251'], Confidence: 1.0\n",
      "Items: ['GRO21487', 'GRO85051'] => ['FRO40251'], Confidence: 1.0\n",
      "Items: ['GRO38814', 'GRO85051'] => ['FRO40251'], Confidence: 1.0\n",
      "Items: ['GRO73461', 'GRO85051'] => ['FRO40251'], Confidence: 1.0\n"
     ]
    }
   ],
   "source": [
    "transaction=[]\n",
    "browsing=open('browsing.txt','r')\n",
    "for line in browsing:\n",
    "    item=line.strip().split()\n",
    "    transaction.append(item)\n",
    "\n",
    "encoder = TransactionEncoder()\n",
    "encoded_transaction = encoder.fit_transform(transaction)\n",
    "\n",
    "# 将转换后的数据转换为DataFrame\n",
    "df = pd.DataFrame(encoded_transaction, columns=encoder.columns_)\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=100/len(transaction),max_len=3,use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "filtered_itemsets = frequent_itemsets[(frequent_itemsets['length'] == 3)]\n",
    "\n",
    "# 3. 生成关联规则\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "# 5. 提取並排序結果\n",
    "# 根据信賴度降序排序，信賴度相同的按字典順序排序\n",
    "sorted_rules = rules.sort_values(by=[\"confidence\", \"antecedents\"], ascending=[False, True])\n",
    "\n",
    "# 6. 打印前五個規則及其信賴度\n",
    "for index, row in sorted_rules.head(5).iterrows():\n",
    "    antecedents = list(row[\"antecedents\"])\n",
    "    consequents = list(row[\"consequents\"])\n",
    "    confidence = row[\"confidence\"]\n",
    "    print(f\"Items: {antecedents} => {consequents}, Confidence: {confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11232c75",
   "metadata": {},
   "source": [
    "## 3  Scalability Comparisons (40 %)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd33c727",
   "metadata": {},
   "source": [
    "### 3.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01415e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8bb3b61",
   "metadata": {},
   "source": [
    "### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea687820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9d08c39",
   "metadata": {},
   "source": [
    "### 3.3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cfbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
